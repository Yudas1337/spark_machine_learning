{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "AE6TlvQzKskb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d1b535f-888e-42e7-c54d-1b41f7de3b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install pyspark\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1TiNcTNL5fX",
        "outputId": "26cbff9c-97dc-4b54-ad28-8a6a006c47cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317130 sha256=b1c94684ccd56df7311dccdf6e750b793a3bd3572261f40cdd80a0f1d46be864\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession, SQLContext"
      ],
      "metadata": {
        "id": "aYYcyYKLLAi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName('Movie Recommendation').getOrCreate()"
      ],
      "metadata": {
        "id": "zyqQWeUoLpG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.sql import Row\n",
        "\n",
        "lines = spark.read.text(\"/content/drive/MyDrive/Colab Notebooks/Bigdata/Week 15/ratings.dat\").rdd\n",
        "parts = lines.map(lambda row: row.value.split(\"::\"))\n",
        "ratingsRDD = parts.map(lambda p: Row(userId=int(p[0]), movieId=int(p[1]),\n",
        "                                     rating=int(p[2]), timestamp=int(p[3])))"
      ],
      "metadata": {
        "id": "6kGDPfyrMTS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3elzb1SKGid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f126fb1b-73ab-49eb-9576-94a9ff7fc553"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+------+---------+----------+\n",
            "|userId|movieId|rating|timestamp|prediction|\n",
            "+------+-------+------+---------+----------+\n",
            "|     1|    260|     4|978300760| 4.3861814|\n",
            "|     1|    661|     3|978302109| 2.8327825|\n",
            "|     1|    919|     4|978301368| 4.7771387|\n",
            "|     1|   1029|     5|978302205| 4.4698286|\n",
            "|     1|   1035|     5|978301753|  4.160609|\n",
            "|     1|   1545|     4|978824139| 3.1587648|\n",
            "|     1|   1721|     4|978300055| 5.1249423|\n",
            "|     1|   2687|     3|978824268| 3.8394065|\n",
            "|     2|    349|     4|978299839| 3.7561812|\n",
            "|     2|    442|     3|978300025| 2.6571643|\n",
            "|     2|    589|     4|978299773| 3.5257268|\n",
            "|     2|    590|     5|978299083| 4.4513745|\n",
            "|     2|    780|     3|978299966| 3.9276054|\n",
            "|     2|    902|     2|978298905| 4.3690367|\n",
            "|     2|    982|     4|978299269|  3.883231|\n",
            "|     2|   1084|     3|978298813| 4.0071673|\n",
            "|     2|   1096|     4|978299386| 3.5872035|\n",
            "|     2|   1193|     5|978298413| 4.3087916|\n",
            "|     2|   1198|     4|978298124|  4.358396|\n",
            "|     2|   1253|     3|978299120|  4.175157|\n",
            "+------+-------+------+---------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ratings = spark.createDataFrame(ratingsRDD)\n",
        "(training, test) = ratings.randomSplit([0.8, 0.2])\n",
        "\n",
        "# Build the recommendation model using ALS on the training data\n",
        "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
        "als = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\")\n",
        "model = als.fit(training)\n",
        "\n",
        "# Evaluate the model by computing the RMSE on the test data\n",
        "predictions = model.transform(test)\n",
        "predictions.show()\n",
        "\n",
        "import math\n",
        "result = predictions.rdd.map(lambda row: row['prediction'] - row['rating']).map(lambda x: x*x).filter(lambda x: not math.isnan(x))\n",
        "mse = result.reduce(lambda x,y: x+y)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uq7xOO5lMCLL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}